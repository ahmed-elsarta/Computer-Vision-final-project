{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect the faces from the webcam and apply PCA on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(reference_faces_vector):\n",
    "    \"\"\"\n",
    "    Creating the PCA model\n",
    "    \n",
    "    ## Parameters \n",
    "    face_vector : contain the training images where each column contain one image of size (N^2 * 1)\n",
    "    \n",
    "    ## Returns\n",
    "    weights : vector contain the similarity between each image and eigen vectors\n",
    "\n",
    "    avg_face_vector : the mean image, used in testing\n",
    "\n",
    "    eigen_faces : contain eigen vectors, used in testing\n",
    "    \"\"\"\n",
    "    #get the mean image\n",
    "    avg_face_vector = reference_faces_vector.mean(axis=1)\n",
    "    avg_face_vector = avg_face_vector.reshape(reference_faces_vector.shape[0], 1)\n",
    "    #subtract the mean image from the images\n",
    "    normalized_face_vector = reference_faces_vector - avg_face_vector\n",
    "\n",
    "    #calculate covariance matrix\n",
    "    covariance_matrix = np.cov(np.transpose(normalized_face_vector)) \n",
    "\n",
    "    #get eigen values and eigen vectors\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "    #select best k eigen vectors . this variable is changable according to the data set\n",
    "    k = 30\n",
    "    index_of_max_k_eigen_values = np.argpartition(eigen_values, -k)[-k:]\n",
    "    k_eigen_vectors = []\n",
    "\n",
    "    for i in range(len(index_of_max_k_eigen_values)):\n",
    "        k_eigen_vectors.append(eigen_vectors[index_of_max_k_eigen_values[i]])\n",
    "\n",
    "    k_eigen_vectors = np.asarray(k_eigen_vectors)\n",
    "\n",
    "    eigen_faces = k_eigen_vectors.dot(normalized_face_vector.T)\n",
    "    weights = (normalized_face_vector.T).dot(eigen_faces.T)\n",
    "\n",
    "    return weights, avg_face_vector, eigen_faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_img, weights, avg_face_vector, eigen_faces):\n",
    "    \"\"\"\n",
    "    Recognize faces in test image\n",
    "\n",
    "    ## Parameters\n",
    "    test_img : image to recognize faces in , it is in gray scale\n",
    "\n",
    "    weights : the weights resulting from PCA model\n",
    "\n",
    "    ave_face_vector : average face from the training images\n",
    "\n",
    "    eigen_faces : eigen vector resulting from PCA model\n",
    "    \n",
    "    ## Returns\n",
    "    index : index of the matched image\n",
    "\n",
    "    \"\"\"\n",
    "    test_img = test_img.reshape(test_img.shape[0] * test_img.shape[1], 1)\n",
    "    test_normalized_face_vector = test_img - avg_face_vector\n",
    "    test_weight = (test_normalized_face_vector.T).dot(eigen_faces.T)\n",
    "    index = np.argmin(np.linalg.norm(test_weight - weights, axis=1))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Set up a list of reference faces\n",
    "directory = 'images'\n",
    "reference_faces = []\n",
    "reference_labels = []\n",
    "\n",
    "# Access the directory that contains all the images folders\n",
    "for foldername in os.listdir(directory):\n",
    "    # Access all the images files in each folder\n",
    "       for filename in os.listdir(directory + '/' + foldername):\n",
    "            # Read each face image and store it and its label in the lists\n",
    "            face_image = cv2.imread(directory + '/' + foldername + '/' + filename, cv2.IMREAD_GRAYSCALE)\n",
    "            reference_faces.append(face_image)\n",
    "            reference_labels.append(foldername)\n",
    "\n",
    "# Convert the lists to arrays\n",
    "reference_faces = np.asarray(reference_faces)\n",
    "reference_labels = np.asarray(reference_labels)\n",
    "\n",
    "reference_faces_vector = []\n",
    "\n",
    "for face in reference_faces:\n",
    "    reference_faces_vector.append(face.flatten())\n",
    "reference_faces_vector = np.asarray(reference_faces_vector).transpose()\n",
    "\n",
    "\n",
    "# Get the weights, eigen vectors and eigen values of the vector\n",
    "weights, avg_face_vector, eigen_faces = PCA(reference_faces_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To capture video from webcam\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read the frame\n",
    "    stream, frame = camera.read()\n",
    "\n",
    "    # Calculate the PCA features of the frame\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Draw a bounding box around the detected face and label it with the closest reference face\n",
    "    faces_detected = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    if len(faces_detected) > 0:\n",
    "        # Initialize an empty list to store the cropped face images\n",
    "\n",
    "        for (x, y, w, h) in faces_detected:\n",
    "            face_cropped_img = gray_frame[y:y+h, x:x+w]\n",
    "            resized_face_cropped_img = cv2.resize(face_cropped_img,(250,250))\n",
    "            closest_idx = test(resized_face_cropped_img, weights, avg_face_vector, eigen_faces)\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"{reference_labels[closest_idx]}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Exit if the key \"q\" is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
