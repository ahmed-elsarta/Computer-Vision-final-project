{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# face detection in python using built in libraries\n",
    "\n",
    "This code loads an image from the file system using the cv2.imread function and displays it using cv2.imshow. It then loads a face detection classifier using the CascadeClassifier method from the opencv-python library.\n",
    "\n",
    "The code applies face detection on the image using the detectMultiScale method and checks if at least one face was detected. If faces are detected, the code loops through all detected faces, crops the original image to just the person's face, and stores it as a separate image using cv2.imwrite. The face images are stored using a unique filename that includes the index of the face.\n",
    "\n",
    "Finally, the code displays the original image with rectangles around the detected faces using cv2.rectangle and waits for a key press before closing the window using cv2.waitKey and cv2.destroyAllWindows. If no faces are detected in the image, the code prints a message indicating that no faces were detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load a random image with a person from the internet\n",
    "img = cv2.imread('img2.jpg', cv2.IMREAD_UNCHANGED)\n",
    "cv2.imshow(\"original Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# load the face detection classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# apply face detection on the image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# check if at least one face was detected\n",
    "if len(faces) > 0:\n",
    "    # loop through all detected faces and store them\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        crop_img = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(f\"face_{i}.jpg\", crop_img)\n",
    "\n",
    "    # display the original image with rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Detected Faces\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No faces were detected in the image.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below we will make this into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed elsarta\\AppData\\Local\\Temp\\ipykernel_19292\\3965793720.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(face_images)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "def detect_and_crop_faces(image_url):\n",
    "    # Load the image from the URL\n",
    "    img = cv2.imread(image_url, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Load the face detection classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    # Apply face detection on the image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Check if at least one face was detected\n",
    "    if len(faces) > 0:\n",
    "        # Initialize an empty list to store the cropped face images\n",
    "        face_images = []\n",
    "\n",
    "        # Loop through all detected faces and store them\n",
    "        for (x, y, w, h) in faces:\n",
    "            crop_img = img[y:y+h, x:x+w]\n",
    "            face_images.append(crop_img)\n",
    "\n",
    "        # Return the array of cropped face images\n",
    "        return np.array(face_images)\n",
    "    else:\n",
    "        print(\"No faces were detected in the image.\")\n",
    "        return None\n",
    "\n",
    "#try it out\n",
    "image_url = \"IMG_0230.JPG\"\n",
    "#show the image in the notebook\n",
    "original_image = cv2.imread(image_url)\n",
    "cv2.imshow(\"original Image\", original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "face_images = detect_and_crop_faces(image_url)\n",
    "if face_images is not None:\n",
    "    # Store image in filesystem then display it\n",
    "    for i in range(len(face_images)):\n",
    "        cv2.imwrite(f\"face_{i}.jpg\", face_images[i])    \n",
    "        cv2.imshow(f\"face_{i}\", face_images[i])\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
