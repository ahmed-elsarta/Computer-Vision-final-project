{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# face detection in python using built in libraries\n",
    "\n",
    "This code loads an image from the file system using the cv2.imread function and displays it using cv2.imshow. It then loads a face detection classifier using the CascadeClassifier method from the opencv-python library.\n",
    "\n",
    "The code applies face detection on the image using the detectMultiScale method and checks if at least one face was detected. If faces are detected, the code loops through all detected faces, crops the original image to just the person's face, and stores it as a separate image using cv2.imwrite. The face images are stored using a unique filename that includes the index of the face.\n",
    "\n",
    "Finally, the code displays the original image with rectangles around the detected faces using cv2.rectangle and waits for a key press before closing the window using cv2.waitKey and cv2.destroyAllWindows. If no faces are detected in the image, the code prints a message indicating that no faces were detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful imports\n",
    "#converting the HEIC files to JPG\n",
    "import os\n",
    "from PIL import Image\n",
    "import pillow_heif\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a random image with a person from the internet\n",
    "img = cv2.imread('IMG_0178.JPG', cv2.IMREAD_UNCHANGED)\n",
    "cv2.imshow(\"original Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# load the face detection classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# apply face detection on the image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# check if at least one face was detected\n",
    "if len(faces) > 0:\n",
    "    # loop through all detected faces and store them\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        crop_img = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(f\"face_{i}.jpg\", crop_img)\n",
    "\n",
    "    # display the original image with rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Detected Faces\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No faces were detected in the image.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below we will make this into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed elsarta\\AppData\\Local\\Temp\\ipykernel_18436\\888129300.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(face_images)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "def detect_and_crop_faces(image_url):\n",
    "    # Load the image from the URL\n",
    "    img = cv2.imread(image_url, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Load the face detection classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    # Apply face detection on the image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Check if at least one face was detected\n",
    "    if len(faces) > 0:\n",
    "        # Initialize an empty list to store the cropped face images\n",
    "        face_images = []\n",
    "\n",
    "        # Loop through all detected faces and store them\n",
    "        for (x, y, w, h) in faces:\n",
    "            crop_img = img[y:y+h, x:x+w]\n",
    "            face_images.append(crop_img)\n",
    "\n",
    "        # Return the array of cropped face images\n",
    "        return np.array(face_images)\n",
    "    else:\n",
    "        print(\"No faces were detected in the image.\")\n",
    "        return None\n",
    "\n",
    "#try it out\n",
    "image_url = \"IMG_0230.JPG\"\n",
    "#show the image in the notebook\n",
    "original_image = cv2.imread(image_url)\n",
    "cv2.imshow(\"original Image\", original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "face_images = detect_and_crop_faces(image_url)\n",
    "if face_images is not None:\n",
    "    # Store image in filesystem then display it\n",
    "    for i in range(len(face_images)):\n",
    "        cv2.imwrite(f\"face_{i}.jpg\", face_images[i])    \n",
    "        cv2.imshow(f\"face_{i}\", face_images[i])\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for converting the HEIC images into png images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diaa (1).HEIC\n",
      "diaa (2).HEIC\n",
      "diaa (3).HEIC\n",
      "diaa (4).HEIC\n",
      "diaa (5).HEIC\n",
      "diaa (6).HEIC\n",
      "diaa (7).HEIC\n",
      "diaa (8).HEIC\n",
      "diaa (9).HEIC\n",
      "IMG_5708.HEIC\n",
      "IMG_5709.HEIC\n",
      "IMG_5710.HEIC\n",
      "saeid (1).HEIC\n",
      "saeid (10).HEIC\n",
      "saeid (11).HEIC\n",
      "saeid (12).HEIC\n",
      "saeid (13).HEIC\n",
      "saeid (14).HEIC\n",
      "saeid (15).HEIC\n",
      "saeid (16).HEIC\n",
      "saeid (17).HEIC\n",
      "saeid (2).HEIC\n",
      "saeid (3).HEIC\n",
      "saeid (4).HEIC\n",
      "saeid (5).HEIC\n",
      "saeid (6).HEIC\n",
      "saeid (7).HEIC\n",
      "saeid (8).HEIC\n",
      "saeid (9).HEIC\n",
      "sarta (1).HEIC\n",
      "sarta (10).HEIC\n",
      "sarta (11).HEIC\n",
      "sarta (12).HEIC\n",
      "sarta (13).HEIC\n",
      "sarta (14).HEIC\n",
      "sarta (15).HEIC\n",
      "sarta (2).HEIC\n",
      "sarta (3).HEIC\n",
      "sarta (4).HEIC\n",
      "sarta (5).HEIC\n",
      "sarta (6).HEIC\n",
      "sarta (7).HEIC\n",
      "sarta (8).HEIC\n",
      "sarta (9).HEIC\n",
      "se3a (1).HEIC\n",
      "se3a (10).HEIC\n",
      "se3a (11).HEIC\n",
      "se3a (2).HEIC\n",
      "se3a (3).HEIC\n",
      "se3a (4).HEIC\n",
      "se3a (5).HEIC\n",
      "se3a (6).HEIC\n",
      "se3a (7).HEIC\n",
      "se3a (8).HEIC\n",
      "se3a (9).HEIC\n",
      "sherif (1).HEIC\n",
      "sherif (10).HEIC\n",
      "sherif (11).HEIC\n",
      "sherif (12).HEIC\n",
      "sherif (2).HEIC\n",
      "sherif (3).HEIC\n",
      "sherif (4).HEIC\n",
      "sherif (5).HEIC\n",
      "sherif (6).HEIC\n",
      "sherif (7).HEIC\n",
      "sherif (8).HEIC\n",
      "sherif (9).HEIC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# directory_in_str = \"../Face_recognition_Images/\"\n",
    "# directory = os.fsencode(directory_in_str)\n",
    "  \n",
    "# for file in os.listdir(directory):\n",
    "#     filename = os.fsdecode(file)\n",
    "#     print(filename)\n",
    "#     if filename.endswith(\".HEIC\"):\n",
    "#         pillow_heif.register_heif_opener()\n",
    "#         img = Image.open(directory_in_str+filename)\n",
    "#         #remove the .HEIC extension\n",
    "#         filename = filename[:-5]\n",
    "#         img.save(\"faces/\"+filename+\".png\", format(\"png\"))        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cropping the faces for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detecting face in diaa (1).png\n",
      "detecting face in diaa (2).png\n",
      "detecting face in diaa (3).png\n",
      "detecting face in diaa (4).png\n",
      "detecting face in diaa (5).png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\college\\year 3 sbme\\2nd term\\computer vision\\face recognition task\\face detection.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/college/year%203%20sbme/2nd%20term/computer%20vision/face%20recognition%20task/face%20detection.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#get the path of the image\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/college/year%203%20sbme/2nd%20term/computer%20vision/face%20recognition%20task/face%20detection.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m url \u001b[39m=\u001b[39m png_faces\u001b[39m+\u001b[39mfilename\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/college/year%203%20sbme/2nd%20term/computer%20vision/face%20recognition%20task/face%20detection.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m original_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(url)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/college/year%203%20sbme/2nd%20term/computer%20vision/face%20recognition%20task/face%20detection.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#detect faces by passing path to function\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/college/year%203%20sbme/2nd%20term/computer%20vision/face%20recognition%20task/face%20detection.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m face_images \u001b[39m=\u001b[39m detect_and_crop_faces(url)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "png_faces = \"faces/\"\n",
    "for file in os.listdir(png_faces):\n",
    "    filename = os.fsdecode(file)\n",
    "    print(\"detecting face in \"+filename)\n",
    "    #get the path of the image\n",
    "    url = png_faces+filename\n",
    "    original_image = cv2.imread(url)\n",
    "    #detect faces by passing path to function\n",
    "    face_images = detect_and_crop_faces(url)\n",
    "    if face_images is not None:\n",
    "        # Store image in filesystem then display it\n",
    "        cv2.imwrite(\"detected faces/\"+filename+\"face.jpg\", face_images[0]) #since we know it's 1 face, take the first one \n",
    "        # cv2.imshow(\"\", face_images[0])\n",
    "        # cv2.waitKey(500) #optional code for showing images\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
